{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wangjona9/AACNestedHW/blob/main/04_AIT_MLP_CIFAR10_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW-EyI5Lxpqi"
      },
      "source": [
        "# Copyright\n",
        "\n",
        "<PRE>\n",
        "Copyright (c) Bálint Gyires-Tóth - All Rights Reserved\n",
        "You may use and modify this code for research and development purpuses.\n",
        "Using this code for educational purposes (self-paced or instructor led) without the permission of the author is prohibited.\n",
        "</PRE>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example of data exploration, modeling, regulartion and prediction\n",
        "Our exercise today involves loading a standard dataset using TensorFlow Keras API, exploring the data, building a simple neural network, and evaluating the effects of basic methods (activation functions, regularization, weight initialization, etc.). We then perform predictions on the test set and inspect the results."
      ],
      "metadata": {
        "id": "3EX4cCa4WKJu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data\n",
        "The dataset we will use is the well-known CIFAR10 (Canadian Institute For Advanced Research). Explore the details on the Keras website first: https://keras.io/api/datasets/cifar10/\n",
        "\n",
        "After you explored the basic features of the data, let's load it into the memory and explore the shapes:"
      ],
      "metadata": {
        "id": "yY9fztIeWIKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "giRZKTjzX_7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "bez7q0eiWQCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "878fa72c-bb72-4a48-89eb-0b3a8925ef01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 8s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)"
      ],
      "metadata": {
        "id": "2tJoRq5wXywi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7b8e6de-2a0b-45b9-81e2-bf80fbf8dee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. Exercise\n",
        "Display the first ten images of the training data. Hints:\n",
        "* Axis 0 refers to the separate images, e.g. X_train[0]\n",
        "* You can use the [Matplotlib Pyplot imshow function](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html) for displaying the image. Just don't forget to import Plotly first!\n",
        "* A corresponding example, but you have to modify the code for your purpose: https://stackoverflow.com/questions/46615554/how-to-display-multiple-images-in-one-figure-correctly"
      ],
      "metadata": {
        "id": "zTCSGFyDlNvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "<TODO>"
      ],
      "metadata": {
        "id": "hIQhHTppmBdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the corresponding labels of the displayed images from the target variable (Y_train):"
      ],
      "metadata": {
        "id": "FAQkUWlmm-bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(<TODO>)"
      ],
      "metadata": {
        "id": "AkOrWzghnJ78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. Exercise\n",
        "We will train a Multi-Layer Perceptron (MLP), which requires a 2 dimensional input: 0th axis refers to the datapoints (i.e. images), the 1th dimens to the input. As images are 3 dimensional (width, height, color channels), you have to reshape the images into vectors. We also call this flattening.\n",
        "\n",
        "In order to do so, calculate the size of the equivalent 1D vector of the image:"
      ],
      "metadata": {
        "id": "VX24g5FstsRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flattened_dim = <TODO>"
      ],
      "metadata": {
        "id": "hdoMyxHzuXZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After you calculated it, we can reshape the images, and covert the integer arrays into float arrays -- which are needed for the neural networks as input. Hint:\n",
        "* in the [reshape() function of Numpy](https://www.w3schools.com/python/numpy/numpy_array_reshape.asp) you can use -1 for one axis, to automatically calculate that value."
      ],
      "metadata": {
        "id": "WbqXJUSFubeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape 3D tensors to 2D tensors\n",
        "X_train = X_train.reshape(<TODO>)\n",
        "X_test = X_test.reshape(<TODO>)\n",
        "\n",
        "# it is in int8 format, the neural network requires float32\n",
        "X_train = X_train.astype(<TODO>)\n",
        "X_test = X_test.astype(<TODO>)"
      ],
      "metadata": {
        "id": "vukOcBM0XzSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3. Exercise\n",
        "As the next step, let's split the training data into training and validation data. 80% of the original training data should be the final training data, and 20% the validation.\n",
        "You should use Numpy indexing to select the first 80% of X_train as final X_train, and the last 20% as X_valid. Hints:\n",
        "* https://datascienceparichay.com/article/numpy-array-first-n-rows/\n",
        "* https://datascienceparichay.com/article/numpy-array-last-n-rows/"
      ],
      "metadata": {
        "id": "DO79AdIdvVfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio  = 0.8\n",
        "train_length = <TODO> # length of the training data\n",
        "train_split  = <TODO> # where to split the training and validation data\n",
        "X_valid, Y_valid = X_train[<TODO>], Y_train[<TODO>]\n",
        "X_train, Y_train = X_train[<TODO>], Y_train[<TODO>]"
      ],
      "metadata": {
        "id": "mRwuWxxIxLgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4. Exercise\n",
        "As the last step of input data preparation, the data should be standardized. Calculate the mean and variance of the training data (elementvise -- so for each value of the flattened image you should get a mean and variance for the training data along 0th axis). Hint:\n",
        "* https://stackoverflow.com/questions/70626231/how-to-calculate-mean-variance-standard-deviation-per-index-of-array"
      ],
      "metadata": {
        "id": "z05y_QWDxWER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = <TODO>\n",
        "std  = <TODO>"
      ],
      "metadata": {
        "id": "TSZbvWCBx8Ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, use the resulting values to standardize the training, validation and test data by substracting the mean and dividing the result with the standard deviation."
      ],
      "metadata": {
        "id": "6WRHKkkjyN1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = <TODO>\n",
        "X_valid = <TODO>\n",
        "X_test  = <TODO>"
      ],
      "metadata": {
        "id": "2ESLP1EIyB2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5. Exercise\n",
        "And as the last step, convert the dense representation of the classes (i.e. 0,1,2,3...9) to one-hot encoding (0 = [1 0 0 0 0 0 0 0 0 0], 1 = [0 1 0 0 0 0 0 0 0 0] ... 9 = [0 0 0 0 0 0 0 0 0 1]). To do this, first, calculate the number of unique elements in the target training data. Hints:\n",
        "* use the [unique() function](https://numpy.org/doc/stable/reference/generated/numpy.unique.html) of Numpy to list the unique elements\n",
        "* you can count the number of elements in a list with the [len() function](https://www.w3schools.com/python/ref_func_len.asp)"
      ],
      "metadata": {
        "id": "ooHCnUin7r4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_classes = <TODO>"
      ],
      "metadata": {
        "id": "i0LAO9cs8KEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doublecheck, if the same number of classes exists in the validation and test target data:"
      ],
      "metadata": {
        "id": "BvM6XhGe8JU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Validation data has the same number of classes, as the training data:\", nb_classes == len(np.unique(Y_valid)))\n",
        "print(\"Test data has the same number of classes, as the training data:\", nb_classes == len(np.unique(Y_test)))"
      ],
      "metadata": {
        "id": "eZFNSsyx_Py2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And convert the dense representation into one-hot encoding. Hint:\n",
        "* use the [to_categorical function](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical) with the calculated nb_classes\n"
      ],
      "metadata": {
        "id": "mJM-iBmR8dLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train = <TODO>\n",
        "Y_valid = <TODO>\n",
        "Y_test  = <TODO>"
      ],
      "metadata": {
        "id": "xwZ4OJ6I8lba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final check of data preparation\n",
        "Now, lets check the shapes and mean and standard deviation of the training, validation and test data."
      ],
      "metadata": {
        "id": "LshN2OSsv3TZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shapes of the training, validation and test input data:\", X_train.shape, X_valid.shape, X_test.shape)\n",
        "print(\"Shapes of the training, validation and test output data:\", Y_train.shape, Y_valid.shape, Y_test.shape)\n",
        "print(\"Mean values of the training, validation and test input data:\", X_train.mean(), X_valid.mean(), X_test.mean())\n",
        "print(\"Standard deviation of the training, validation and test input data:\", X_train.std(), X_valid.std(), X_test.std())"
      ],
      "metadata": {
        "id": "O_jdJVcvX0vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Don't worry, if the mean and standard deviation of the validation and test data are not exactly 0 and 1, but these might be very mear to it (e.g. 0.01 mean, 0.99 variance)."
      ],
      "metadata": {
        "id": "5GtAOOoezmZY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ14oyZExpqj"
      },
      "source": [
        "# 2. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4ZXYRMBxpql"
      },
      "source": [
        "Let us begin with a simple example of creating a small neural network without regularization and training it with actual data. The purpose of this is to provide you with an example as to how to proceed with the next exercise."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten, Dropout\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "6-8Q6ll7ZDgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model definition\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='tanh', input_shape=(flattened_dim,)))\n",
        "model.add(Dense(128, activation='tanh'))\n",
        "model.add(Dense(nb_classes, activation='softmax'))\n",
        "\n",
        "# loss function and optimizer\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "pke6w3CD8DHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZbOR76QxprC"
      },
      "source": [
        "# training\n",
        "network_history = model.fit(X_train, Y_train,\n",
        "                            validation_data=(X_valid,Y_valid),\n",
        "                            batch_size=128,\n",
        "                            epochs=40,\n",
        "                            verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFqhzV85xprJ"
      },
      "source": [
        "Let's plot the training and validation loss and accuracy curves:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYmXGkLCxprK"
      },
      "source": [
        "def plot_history(network_history):\n",
        "    plt.figure()\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.plot(network_history.history['loss'])\n",
        "    plt.plot(network_history.history['val_loss'])\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "\n",
        "    plt.figure()\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.plot(network_history.history['accuracy'])\n",
        "    plt.plot(network_history.history['val_accuracy'])\n",
        "    plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "plot_history(network_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What do you think? Does it overfit?"
      ],
      "metadata": {
        "id": "tgG7QeXF-dx6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q9rIeBBxprO"
      },
      "source": [
        "# Inspecting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r2AmmoMxprP"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3-bVDVuxprS"
      },
      "source": [
        "print('Input: ', model.input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da2OJ3DmxprX"
      },
      "source": [
        "print('Layers:\\n')\n",
        "for layer in model.layers:\n",
        "    print(\"Layer's name: \", layer.name, ', trainable: ', layer.trainable)\n",
        "    print(layer.get_config(),'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtVX3M3lxprc"
      },
      "source": [
        "print('Output: ', model.output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. Exercise\n",
        "Introduce [early stopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) and [dropout](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) with a rate between 0.1..0.5. Tips:\n",
        "\n",
        "* Insert the dropout layer between the two Dense layers.\n",
        "* Set the patience of early stopping to 5.\n",
        "* Set the number of epochs to a very high number.\n",
        "* Don't forget to restore best weights after early stopping.\n",
        "* And also set early stopping to monitor validation accuracy (the default value is validation loss -- which is categorical crossentropy now).\n",
        "\n",
        "Compile and train the model. Attempt to increase the validation accuracy as much as possible by making changes to the dropout rate. Inspect the effects of the modifications."
      ],
      "metadata": {
        "id": "E-hHfs9qA_iO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es = <TODO>"
      ],
      "metadata": {
        "id": "NwXrPzOgEBG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model definition with dropout\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='tanh', input_shape=(flattened_dim,)))\n",
        "<TODO>\n",
        "model.add(Dense(128, activation='tanh'))\n",
        "model.add(Dense(nb_classes, activation='softmax'))\n",
        "\n",
        "# loss function and optimizer\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "7hZEGzj8GFwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training with early stopping\n",
        "network_history = model.fit(X_train, Y_train,\n",
        "                            validation_data=(X_valid,Y_valid),\n",
        "                            batch_size=128,\n",
        "                            epochs=<TODO>,\n",
        "                            verbose=1,\n",
        "                            callbacks=[<TODO>])"
      ],
      "metadata": {
        "id": "GCG54R-vGGWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Exercise\n",
        "Change the [activation function of the dense layers (except the last one)](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) to rectified linear unit (ReLU) and the [weight initialization](https://www.tensorflow.org/api_docs/python/tf/keras/initializers) to the theoretically best one. Use the original model's code.\n",
        "\n",
        "Compile and train the model. Inspect the effects of the modifications."
      ],
      "metadata": {
        "id": "zQCDM1o1BBtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model definition with relu\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='<TODO>', kernel_initializer=<TODO>, input_shape=(flattened_dim,)))\n",
        "model.add(Dense(128, activation='<TODO>', kernel_initializer=<TODO>))\n",
        "model.add(Dense(nb_classes, activation='softmax'))\n",
        "\n",
        "# loss function and optimizer\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "YjHAAh-wGu9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "network_history = model.fit(X_train, Y_train,\n",
        "                            validation_data=(X_valid,Y_valid),\n",
        "                            batch_size=128,\n",
        "                            epochs=40,\n",
        "                            verbose=1)"
      ],
      "metadata": {
        "id": "rarwKM1wGxMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.3. Exercise\n",
        "Based on the modifications above, and by any further modifications (e.g. more layers, less layers, more neurons/layer, etc.) to the model design, find a combination that is able to achieve **validation accuracy, that is higher than 53%**.\n"
      ],
      "metadata": {
        "id": "j1tGVPdD-pp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es = <TODO>"
      ],
      "metadata": {
        "id": "5dBQxJHIHrbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model definition\n",
        "model = Sequential()\n",
        "<TODO>\n",
        "\n",
        "# loss function and optimizer\n",
        "model.compile(<TODO>)"
      ],
      "metadata": {
        "id": "PuxHOqLt-3Nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "network_history = model.fit(<TODO>)"
      ],
      "metadata": {
        "id": "u8tFNCNVHyt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Evaluation on test data and inference\n",
        "At this point, we will perform a basic evaluation and inference. With the model.evaluate function, the same metrics are calculated, that were used during training:"
      ],
      "metadata": {
        "id": "2FtKp-a2-A9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.evaluate(X_test, Y_test))"
      ],
      "metadata": {
        "id": "I3_9wgDREUna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we would like to see similar values, as in the validation set. If those are close to each other, then the generalization ability of the model is good (in case of an independent test-set)."
      ],
      "metadata": {
        "id": "ECHguBFtGL7f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. Exercise\n",
        "Predict the class of the first 10 elements in the test set, and compare the predicted values with the actual, target values in the test set. Hints:\n",
        "* you can use [model.predict](https://www.activestate.com/resources/quick-reads/how-to-use-a-model-to-do-predictions-with-keras/) for prediction\n",
        "* from the output you can select the largest value with the [argmax() function of Numpy](https://stackoverflow.com/questions/62358642/convert-one-hot-encoding-back-to-number-label). As there are multiple values, you have to call it with axis=1 parameter.\n",
        "* it is enought to compare the predictions and the targets by printing the values out and inspecting them."
      ],
      "metadata": {
        "id": "0Io4zYJeHjz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = <TODO>\n",
        "preds_dense = <TODO>"
      ],
      "metadata": {
        "id": "XEEyU7exILqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before comparision, you have to convert back the one-hot encoded target values the same way, as you converted the output of the neural network to class values with argmax() function."
      ],
      "metadata": {
        "id": "seZTEFI-I5cZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Target labels:\", np.argmax(Y_test[:10],axis=1))\n",
        "print(\"Predicted labels:\", preds_dense)"
      ],
      "metadata": {
        "id": "PHLvoMuIIkJ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}